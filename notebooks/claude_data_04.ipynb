{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17824/1304668421.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(['player_id', 'season']).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
      "/home/gin-g/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 162\u001b[0m\n\u001b[1;32m    159\u001b[0m current_week \u001b[38;5;241m=\u001b[39m week\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Update models with new week's data\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[43mupdate_models_for_new_week\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_week\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_season\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Make predictions for the next week\u001b[39;00m\n\u001b[1;32m    165\u001b[0m predict_next_week(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatrick Mahomes\u001b[39m\u001b[38;5;124m\"\u001b[39m, df, models, preprocessor, current_week, current_season)\n",
      "Cell \u001b[0;32mIn[3], line 150\u001b[0m, in \u001b[0;36mupdate_models_for_new_week\u001b[0;34m(current_week, current_season)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m df, models, preprocessor\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Update data with new week's results\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_data_with_new_week\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_week\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_season\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Retrain models with updated data\u001b[39;00m\n\u001b[1;32m    153\u001b[0m models, preprocessor \u001b[38;5;241m=\u001b[39m create_and_train_models(df)\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mupdate_data_with_new_week\u001b[0;34m(current_df, new_week, current_season)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_data_with_new_week\u001b[39m(current_df, new_week, current_season):\n\u001b[0;32m---> 34\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mimport_weekly_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_season\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m new_data[new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m new_week]\n\u001b[1;32m     36\u001b[0m     updated_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([current_df, new_data], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nfl_data_py/__init__.py:236\u001b[0m, in \u001b[0;36mimport_weekly_data\u001b[0;34m(years, columns, downcast)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# read weekly data\u001b[39;00m\n\u001b[1;32m    235\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/nflverse/nflverse-data/releases/download/player_stats/player_stats_\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 236\u001b[0m data \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mconcat([pandas\u001b[38;5;241m.\u001b[39mread_parquet(url\u001b[38;5;241m.\u001b[39mformat(x), engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m years])\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[columns]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nfl_data_py/__init__.py:236\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# read weekly data\u001b[39;00m\n\u001b[1;32m    235\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/nflverse/nflverse-data/releases/download/player_stats/player_stats_\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 236\u001b[0m data \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m years])\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[columns]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parquet.py:396\u001b[0m, in \u001b[0;36mFastParquetImpl.read\u001b[0;34m(self, path, columns, filters, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     parquet_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fsspec\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(storage_options \u001b[38;5;129;01mor\u001b[39;00m {}))\u001b[38;5;241m.\u001b[39mfs\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# use get_handle only when we are very certain that it is not a directory\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     path \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nfl_data_py import import_weekly_data, import_players, import_rosters, import_schedules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Global variables\n",
    "seasons = list(range(2018, 2024))\n",
    "target_cols = ['passing_yards', 'attempts', 'completions', \n",
    "               'rushing_yards', 'carries', \n",
    "               'receiving_yards', 'targets', 'receptions']\n",
    "categorical_features = ['position_x', 'recent_team']\n",
    "numerical_features = target_cols\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(seasons):\n",
    "    player_stats = pd.concat([import_weekly_data(seasons)])\n",
    "    players = import_players()\n",
    "    df = pd.merge(player_stats, players, left_on='player_id', right_on='gsis_id', how='left')\n",
    "    df = df.sort_values(['player_id', 'season', 'week'])\n",
    "\n",
    "    for col in target_cols:\n",
    "        df[f'next_week_{col}'] = df.groupby(['player_id', 'season'])[col].shift(-1)\n",
    "\n",
    "    df = df.groupby(['player_id', 'season']).apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Function to update data with new weekly results\n",
    "def update_data_with_new_week(current_df, new_week, current_season):\n",
    "    new_data = import_weekly_data([current_season])\n",
    "    new_data = new_data[new_data['week'] == new_week]\n",
    "    updated_df = pd.concat([current_df, new_data], ignore_index=True)\n",
    "    updated_df = updated_df.sort_values(['player_id', 'season', 'week'])\n",
    "\n",
    "    for col in target_cols:\n",
    "        updated_df[f'next_week_{col}'] = updated_df.groupby(['player_id', 'season'])[col].shift(-1)\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "# Function to create and train models\n",
    "def create_and_train_models(df):\n",
    "    X = df[categorical_features + numerical_features]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(sparse=False, handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    input_dim = X_transformed.shape[1]\n",
    "    \n",
    "    models = {}\n",
    "    for stat in target_cols:\n",
    "        y = df[f'next_week_{stat}'].values\n",
    "        mask = ~np.isnan(y)\n",
    "        X_stat = X_transformed[mask]\n",
    "        y_stat = y[mask]\n",
    "        \n",
    "        model = Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_stat, y_stat, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        models[stat] = model\n",
    "    \n",
    "    return models, preprocessor\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_next_week(player_name, df, models, preprocessor, current_week, current_season):\n",
    "    try:\n",
    "        latest_rosters = import_rosters([current_season])\n",
    "        player_matches = latest_rosters[latest_rosters['player_name'].str.contains(player_name, case=False, na=False)]\n",
    "        \n",
    "        if player_matches.empty:\n",
    "            print(f\"Error: Player '{player_name}' not found in the latest roster.\")\n",
    "            return None\n",
    "        \n",
    "        if len(player_matches) > 1:\n",
    "            print(f\"Multiple matches found for '{player_name}'. Using the first match.\")\n",
    "        \n",
    "        player_info = player_matches.iloc[0]\n",
    "        \n",
    "        player_stats = df[(df['player_id'] == player_info['player_id']) & \n",
    "                          (df['season'] == current_season) & \n",
    "                          (df['week'] == current_week)]\n",
    "        \n",
    "        if player_stats.empty:\n",
    "            print(f\"Error: No stats found for '{player_name}' in week {current_week}.\")\n",
    "            return None\n",
    "        \n",
    "        last_stats = player_stats.iloc[0]\n",
    "        \n",
    "        input_data = pd.DataFrame({col: [last_stats[col]] for col in numerical_features})\n",
    "        input_data['position_x'] = [player_info['position']]\n",
    "        input_data['recent_team'] = [player_info['team']]\n",
    "        \n",
    "        input_transformed = preprocessor.transform(input_data)\n",
    "        \n",
    "        predictions = {stat: models[stat].predict(input_transformed)[0][0] for stat in target_cols}\n",
    "        \n",
    "        print(f\"Week {current_week + 1} Prediction for {player_name}:\")\n",
    "        print(f\"Team: {player_info['team']}\")\n",
    "        print(f\"Position: {player_info['position']}\")\n",
    "        \n",
    "        if player_info['position'] in ['QB']:\n",
    "            print(f\"Predicted passing yards: {predictions['passing_yards']:.2f}\")\n",
    "            print(f\"Predicted passing attempts: {predictions['attempts']:.2f}\")\n",
    "            print(f\"Predicted passing completions: {predictions['completions']:.2f}\")\n",
    "            print(f\"Predicted rushing yards: {predictions['rushing_yards']:.2f}\")\n",
    "            print(f\"Predicted rushing attempts: {predictions['carries']:.2f}\")\n",
    "        elif player_info['position'] in ['RB']:\n",
    "            print(f\"Predicted rushing yards: {predictions['rushing_yards']:.2f}\")\n",
    "            print(f\"Predicted rushing attempts: {predictions['carries']:.2f}\")\n",
    "            print(f\"Predicted receiving yards: {predictions['receiving_yards']:.2f}\")\n",
    "            print(f\"Predicted targets: {predictions['targets']:.2f}\")\n",
    "            print(f\"Predicted receptions: {predictions['receptions']:.2f}\")\n",
    "        elif player_info['position'] in ['WR', 'TE']:\n",
    "            print(f\"Predicted receiving yards: {predictions['receiving_yards']:.2f}\")\n",
    "            print(f\"Predicted targets: {predictions['targets']:.2f}\")\n",
    "            print(f\"Predicted receptions: {predictions['receptions']:.2f}\")\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main execution flow\n",
    "current_season = 2024\n",
    "current_week = 0  # Start with week 0 (preseason)\n",
    "\n",
    "# Initial data load and model training\n",
    "df = load_and_preprocess_data(seasons)\n",
    "models, preprocessor = create_and_train_models(df)\n",
    "\n",
    "# Function to update models for a new week\n",
    "def update_models_for_new_week(current_week, current_season):\n",
    "    global df, models, preprocessor\n",
    "    \n",
    "    # Update data with new week's results\n",
    "    df = update_data_with_new_week(df, current_week, current_season)\n",
    "    \n",
    "    # Retrain models with updated data\n",
    "    models, preprocessor = create_and_train_models(df)\n",
    "    \n",
    "    print(f\"Models updated with data from Week {current_week}\")\n",
    "\n",
    "# Example usage for the first few weeks of the season\n",
    "for week in range(1):  # Weeks 1 to 3\n",
    "    current_week = week\n",
    "    \n",
    "    # Update models with new week's data\n",
    "    update_models_for_new_week(current_week, current_season)\n",
    "    \n",
    "    # Make predictions for the next week\n",
    "    predict_next_week(\"Patrick Mahomes\", df, models, preprocessor, current_week, current_season)\n",
    "    predict_next_week(\"Christian McCaffrey\", df, models, preprocessor, current_week, current_season)\n",
    "    predict_next_week(\"Justin Jefferson\", df, models, preprocessor, current_week, current_season)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "# You can continue this process for the entire season"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
