{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "from nfl_data_py import import_players, import_weekly_data\n",
    "\n",
    "# Fetch player stats data\n",
    "player_stats = import_weekly_data([2022])\n",
    "\n",
    "# Fetch player metadata\n",
    "players = import_players()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22862/3283583966.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('player_id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Combine player stats and player metadata into a single DataFrame\n",
    "df = pd.merge(player_stats, players, left_on='player_id', right_on='gsis_id', how='left')\n",
    "\n",
    "# Sort the dataframe by player_id and week\n",
    "df = df.sort_values(['player_id', 'week'])\n",
    "\n",
    "# Create the target variable (next week's passing yards)\n",
    "df['next_week_passing_yards'] = df.groupby('player_id')['passing_yards'].shift(-1)\n",
    "\n",
    "# Remove the last week for each player (as we don't have next week's data for it)\n",
    "df = df.groupby('player_id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "df['position_x'] = label_encoder.fit_transform(df['position_x'])\n",
    "df['recent_team'] = label_encoder.fit_transform(df['recent_team'])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "df[['passing_yards', 'rushing_yards', 'receiving_yards']] = scaler.fit_transform(df[['passing_yards', 'rushing_yards', 'receiving_yards']])\n",
    "\n",
    "# Remove rows with NaN values\n",
    "df = df.dropna(subset=['next_week_passing_yards', 'passing_yards', 'rushing_yards', 'receiving_yards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['position_x', 'recent_team', 'passing_yards', 'rushing_yards', 'receiving_yards']]\n",
    "y = df['next_week_passing_yards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 09:03:48.499722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-26 09:03:49.417463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 09:03:50.320919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:50.390274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:50.394007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:50.398559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:50.402032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:50.405440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:51.286206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:51.288521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:51.290665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-26 09:03:51.292774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory:  -> device: 0, name: Quadro T1000, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-08-26 09:03:52.695772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ae6a724fac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-26 09:03:52.695792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro T1000, Compute Capability 7.5\n",
      "2024-08-26 09:03:52.717964: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-26 09:03:52.843232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2024-08-26 09:03:53.019156: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 3s 3ms/step - loss: 5935.6655 - val_loss: 4026.5369\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 4688.5513 - val_loss: 2651.9541\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2280.9663 - val_loss: 1366.1849\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 1120.7733 - val_loss: 1278.5441\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1021.1524 - val_loss: 1275.9760\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1001.8184 - val_loss: 1258.5110\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 985.4756 - val_loss: 1246.4224\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 962.6625 - val_loss: 1183.2515\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 948.0475 - val_loss: 1169.1630\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 924.0114 - val_loss: 1196.8280\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 913.5803 - val_loss: 1180.3484\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 903.6169 - val_loss: 1185.8015\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 908.9612 - val_loss: 1123.9296\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 893.1611 - val_loss: 1142.2142\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 889.6011 - val_loss: 1115.7386\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 882.9816 - val_loss: 1088.7924\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 884.3364 - val_loss: 1090.6559\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 871.7586 - val_loss: 1120.0105\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 870.2637 - val_loss: 1064.3645\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 869.0778 - val_loss: 1108.2833\n",
      "Epoch 21/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 866.5139 - val_loss: 1126.1665\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 863.8528 - val_loss: 1059.3080\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 869.1627 - val_loss: 1070.7750\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 857.6249 - val_loss: 1058.9626\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 858.5840 - val_loss: 1080.2098\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 857.7729 - val_loss: 1054.1025\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 854.6295 - val_loss: 1082.5055\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 850.3322 - val_loss: 1074.4559\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 850.6254 - val_loss: 1052.9961\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 847.9664 - val_loss: 1034.1952\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 846.8943 - val_loss: 1047.0479\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 847.3052 - val_loss: 1054.0179\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 844.8549 - val_loss: 1025.8975\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 845.6805 - val_loss: 1033.6578\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 838.8707 - val_loss: 1038.9652\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 838.1628 - val_loss: 1028.0743\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 841.7117 - val_loss: 1085.3390\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 843.7181 - val_loss: 1024.0400\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 839.4799 - val_loss: 1030.6736\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 837.2963 - val_loss: 1061.1523\n",
      "Epoch 41/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 836.1493 - val_loss: 1058.0328\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 838.5606 - val_loss: 1039.8053\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 830.7645 - val_loss: 1014.4341\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 831.5086 - val_loss: 1039.9440\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 834.1382 - val_loss: 1020.6779\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 826.6325 - val_loss: 1033.4330\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 837.2671 - val_loss: 989.6305\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 830.2885 - val_loss: 1007.8122\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 828.5178 - val_loss: 1036.3569\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 825.1725 - val_loss: 1021.7545\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 829.8726 - val_loss: 999.5905\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 821.3213 - val_loss: 1053.8701\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 823.5811 - val_loss: 1060.5659\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 822.1808 - val_loss: 1044.2458\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 829.2347 - val_loss: 1028.1409\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 822.2864 - val_loss: 1016.6549\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 822.2151 - val_loss: 1035.2557\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 818.7773 - val_loss: 1001.4457\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 822.2130 - val_loss: 1028.7161\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 820.3624 - val_loss: 992.5878\n",
      "Epoch 61/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 819.1744 - val_loss: 1023.3682\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 825.0106 - val_loss: 1018.3243\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 814.9456 - val_loss: 987.6750\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 818.6346 - val_loss: 1014.4271\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 818.5494 - val_loss: 991.1169\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 821.7615 - val_loss: 1064.1018\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 818.4122 - val_loss: 968.8828\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 815.1689 - val_loss: 994.6433\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 817.5813 - val_loss: 1074.5481\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 818.8638 - val_loss: 1006.0861\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 824.0896 - val_loss: 1047.8861\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 823.5822 - val_loss: 970.0446\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 821.8486 - val_loss: 1025.4860\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 810.6028 - val_loss: 985.8575\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 814.0707 - val_loss: 988.4962\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 812.9796 - val_loss: 1002.2497\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 808.6964 - val_loss: 1010.2087\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 816.0377 - val_loss: 997.2308\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 816.7737 - val_loss: 998.1130\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 814.6977 - val_loss: 1053.6270\n",
      "Epoch 81/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 811.3615 - val_loss: 1063.5022\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 821.0934 - val_loss: 1037.3467\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 804.9255 - val_loss: 978.5023\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 808.8743 - val_loss: 1025.4097\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 811.0392 - val_loss: 1000.3203\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 808.5844 - val_loss: 982.7982\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 812.5518 - val_loss: 985.6049\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 809.6796 - val_loss: 990.2440\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 807.6879 - val_loss: 1022.3900\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 809.9878 - val_loss: 991.9769\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 809.9832 - val_loss: 993.5630\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 811.6221 - val_loss: 1046.8704\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 806.2646 - val_loss: 973.3282\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 821.6490 - val_loss: 1017.4390\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 813.3759 - val_loss: 1017.8483\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 811.1016 - val_loss: 985.3437\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 806.7321 - val_loss: 1005.1789\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 809.8150 - val_loss: 1024.9681\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 810.4774 - val_loss: 997.1187\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 807.6904 - val_loss: 1043.4606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7836e6ebb640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(5,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: P.Mahomes (ID: 00-0033873)\n",
      "Position: 4\n",
      "Team: 15\n",
      "Current week stats:\n",
      "  Passing yards: 4.503370548490142\n",
      "  Rushing yards: -0.28853030402544877\n",
      "  Receiving yards: -0.8017950927505366\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "Predicted next week's passing yards: 273.007568359375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select a player (in this case, the first one in the DataFrame)\n",
    "player_name = \"Patrick Mahomes\"  # Replace with the name of the player you're interested in\n",
    "player_stats = df[df['player_display_name'] == player_name].iloc[0]\n",
    "\n",
    "# Print player information\n",
    "print(f\"Player: {player_stats['player_name']} (ID: {player_stats['player_id']})\")\n",
    "print(f\"Position: {player_stats['position_x']}\")\n",
    "print(f\"Team: {player_stats['recent_team']}\")\n",
    "print(f\"Current week stats:\")\n",
    "print(f\"  Passing yards: {player_stats['passing_yards']}\")\n",
    "print(f\"  Rushing yards: {player_stats['rushing_yards']}\")\n",
    "print(f\"  Receiving yards: {player_stats['receiving_yards']}\")\n",
    "\n",
    "input_data = np.array([[\n",
    "    player_stats['position_x'],\n",
    "    player_stats['recent_team'],\n",
    "    player_stats['passing_yards'],\n",
    "    player_stats['rushing_yards'],\n",
    "    player_stats['receiving_yards']\n",
    "]])\n",
    "\n",
    "next_week_passing_yards = None\n",
    "\n",
    "try:\n",
    "    prediction = model.predict(input_data)\n",
    "    \n",
    "    if prediction.shape == (1, 1):\n",
    "        next_week_passing_yards = prediction[0][0]\n",
    "        print(f\"\\nPredicted next week's passing yards: {next_week_passing_yards}\")\n",
    "    else:\n",
    "        print(f\"\\nUnexpected prediction shape: {prediction.shape}\")\n",
    "        print(f\"Prediction content: {prediction}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during prediction: {e}\")\n",
    "\n",
    "if next_week_passing_yards is None:\n",
    "    print(\"\\nFailed to generate a valid prediction.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
